{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**취미 추천 AI 모델**\n",
        "> MBTI 성격 유형 테스트를 기반으로 취미를 추천해주는 다중 분류 기반 추천 시스템\n",
        "\n",
        ">"
      ],
      "metadata": {
        "id": "uB472U8_lTxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AI 모듈 구상도**\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?export=view&id=1vzHVlu8IVOHjWNHG6Z3ODDbah-6YAxyk\">"
      ],
      "metadata": {
        "id": "xOyxcgmsjuY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 구성"
      ],
      "metadata": {
        "id": "2yQF7yTRmNOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 취미를 선정하고, 각 취미에 대한 검색결과를 크롤링하였다.\n",
        "* 크롤링한 각 문장들에서 MBTI와 관련된 키워드들을 추출하여 json 형식으로 저장하였다.\n",
        "* 추출한 키워드들과 MBTI 간의 연관성을 알아보기 위해 유사도를 판단하였다."
      ],
      "metadata": {
        "id": "7X2H-BVnmSEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = {\n",
        "    # 속성 추가 예정\n",
        "    'E': [\"외향 -- --\"]\n",
        "    'I': [\"내향 -- --\"]\n",
        "    'N': [\"직관 -- --\"]\n",
        "    'S': [\"감각 -- --\"]\n",
        "    'F': [\"감정 -- --\"]\n",
        "    'T': [\"사고 -- --\"]\n",
        "    'J': [\"판단 -- --\"]\n",
        "    'P': [\"인식 -- --\"]\n",
        "}"
      ],
      "metadata": {
        "id": "EqIXBIoMnFCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_crawling = {\n",
        "    # 속성 추가 예정\n",
        "    '캠핑': [\"-- -- -- --\"]\n",
        "    '야구': [\"-- -- -- --\"]\n",
        "    '전시회 관람': [\"-- -- -- --\"]\n",
        "    '그림 그리기': [\"-- -- -- --\"]\n",
        "    ...\n",
        "}"
      ],
      "metadata": {
        "id": "sXCo6m-vsvNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**유사도 판단**\n",
        "> MBTI는 4가지 카테고리(E/I, N/S, F/T, J/P)로 구성되어 있기 때문에, </br>\n",
        "각 카테고리에서 [E, N, F, J]를 기준으로 키워드 간의 유사도를 비교하여 데이터셋을 재구성하였다.\n",
        "\n",
        "> 자연어 처리에서 TF-IDF, Cosine 유사도 판단 기법을 사용하였다.\n",
        "* TF-IDF : 문서 집합에서 한 단어가 얼마나 중요한지를 수치적으로 나타낸 가중치이다.\n",
        "* Cosine Similarity : 벡터 사이의 각도를 계산하여 두 벡터가 얼마나 유사한지를 측정하는 기법이다."
      ],
      "metadata": {
        "id": "JU1DjP_rntpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사도 판단 함수\n",
        "def get_score(sentences, hobby, category):\n",
        "    sentences = data_crawling[hobby]\n",
        "    s_len = len(sentences)\n",
        "    compare = keywords[category]\n",
        "    sentences = compare + sentences\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "    val = cosine_similarity(tfidf_matrix[0:1],tfidf_matrix[1:]).tolist()[0]\n",
        "    val.sort(reverse=True)\n",
        "    total = s_len - val.count(0.0)\n",
        "    try:\n",
        "        return sum(val)/total\n",
        "    except:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "pGvNcmPUjjoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**취미와 MBTI 속성 간의 유사도를 비교하여 재구성한 데이터셋 예시**"
      ],
      "metadata": {
        "id": "dahNasCCkdHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    ...\n",
        "    \"캠핑\" : [1, 2, 1, 1],\n",
        "    \"야구\" : [2, 1, 0, 1],\n",
        "    \"전시회 관람\" : [2, 0, 1, 0],\n",
        "    \"그림 그리기\" : [1, 0, 0, 1],\n",
        "    ...\n",
        "}"
      ],
      "metadata": {
        "id": "P3icIwZ9k9Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader\n",
        "재구성한 JSON 파일에서 데이터를 로드하고 처리한다.\n",
        "* 각 취미와 MBTI 속성 간의 유사도를 비교한 데이터셋이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "lqDjav6cKJDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R6YNnV0KEGe"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, data_path):\n",
        "        with open(data_path, 'r', encoding='utf8') as f:\n",
        "            self.data_json = json.load(f)\n",
        "\n",
        "            self.num2hobby = {}\n",
        "            self.scores = []\n",
        "            for idx, key in enumerate(self.data_json):\n",
        "                self.num2hobby[idx] = key\n",
        "                self.scores.append(self.data_json[key])\n",
        "\n",
        "            self.position_score = []\n",
        "            self.score_bias = []\n",
        "\n",
        "        def setBias(self, position_score):\n",
        "            self.position_score = position_score\n",
        "\n",
        "            for idx in range(len(position_score)):\n",
        "                if idx == 0:\n",
        "                    self.score_bias.append(0)\n",
        "                else:\n",
        "                    self.score_bias.append(sum(position_score[:idx]))\n",
        "\n",
        "        def getDatasetWithBias(self):\n",
        "            scores_with_bias = []\n",
        "            for score in self.scores:\n",
        "                score_to_data = [(a+b-1) for a, b in zip(score, self.score_bias)]\n",
        "                scores_with_bias.append(score_to_data)\n",
        "\n",
        "            return scores_with_bias\n",
        "\n",
        "        def getDataWithBias(self, score):\n",
        "            return [(a+b-1) for a, b in zip(score, self.score_bias)]\n",
        "\n",
        "        def getNum2Hobby(self):\n",
        "            return self.num2hobby\n",
        "\n",
        "        def getLen(self):\n",
        "            return len(self.scores[0])\n",
        "\n",
        "        def getCount(self):\n",
        "            return len(self.scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "QCGJq0JPsDeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from dataloader import DataLoader\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 문장을 벡터화하는 함수\n",
        "def vectorize_sequences(sequences, dimension):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        sequence = list(sequence)\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--data_path', type==str, default='data/dataset.json')\n",
        "    parser.add_argument('--epoch', type=int, default=100)\n",
        "    parser.add_argument('--batch_size', type=int, default=5)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # 데이터 전처리\n",
        "    dl = DataLoader(args.data_path)\n",
        "    position_score = [4,4,4,4]\n",
        "    shape_X = sum(position_score)\n",
        "    dl.setBias(postion_score)\n",
        "\n",
        "    X_labels = np.array([i for i in range(dl.getCount())])\n",
        "    num2hobby = dl.getNum2Hobby()\n",
        "    scores_with_bias = dl.getDatasetWithBias()\n",
        "\n",
        "    X_train = vectorize_sequences(scores_with_bias, sum(postion_score))\n",
        "    one_hot_train_labels = to_categorical(X_labels)\n",
        "\n",
        "    # 모델 생성\n",
        "    model = models.Sequential()\n",
        "    # 신경망 ReLu\n",
        "    model.add(layers.Dense(40, activation='relu', input_shape=(shape_X,)))\n",
        "    model.add(layers.Dense(20, activation='relu'))\n",
        "    # 출력층\n",
        "    model.add(layers.Dense(dl.getCount(), activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(X_train,\n",
        "                        one_hot_train_labels,\n",
        "                        epochs=args.epoch,\n",
        "                        batch_size=args.batch_size\n",
        "                        )\n",
        "\n",
        "    # Loss 시각화\n",
        "    loss = history.history['loss']\n",
        "\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='train loss')\n",
        "    plt.title('train and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # 모델 저장\n",
        "    model.save('./hobby_model.h5')"
      ],
      "metadata": {
        "id": "Xz1CV1o_sGhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "hoCtoGjEoXkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def vectorize_sequences(sequences, dimension):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        sequence = list(sequence)\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "class PredictModule:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.score_bias = []\n",
        "        # 파일명 수정 예정\n",
        "        with open('취미 json 파일', encoding='utf8') as f:\n",
        "            hobby_info = json.load(f)\n",
        "            self.position_score = hobby_info[\"list\"]\n",
        "            self.num2hobby = hobby_info[\"hobby_enum\"]\n",
        "\n",
        "        for idx in range(len(self.position_score)):\n",
        "            if idx == 0:\n",
        "                self.score_bias.append(0)\n",
        "            else:\n",
        "                self.score_bias.append(sum(self.position_score[:idx]))\n",
        "\n",
        "        def predict(self, user_answer):\n",
        "            question_type = [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]\n",
        "            predict_score = [0, 0, 0, 0]\n",
        "            user_mbti = ''\n",
        "            for q_type, u_answer in zip(question_type, user_answer):\n",
        "                if u_answer == 2: predict_score[q_type] += 1\n",
        "\n",
        "            if predict_score[0] >= 2: user_mbti += 'E'\n",
        "            else: user_mbti += 'I'\n",
        "            if predict_score[1] >= 2: user_mbti += 'N'\n",
        "            else: user_mbti += 'S'\n",
        "            if predict_score[2] >= 2: user_mbti += 'F'\n",
        "            else: user_mbti += 'T'\n",
        "            if predict_score[3] >= 2: user_mbti += 'J'\n",
        "            else: user_mbti += 'P'\n",
        "\n",
        "            X_predict = [(a+b-1) for a, b in zip(predict_score, self.score_bias)]\n",
        "            X_predict = vectorize_sequences([X_predict], sum(self.position_score))\n",
        "            predictions = self.model.predict(X_predict)\n",
        "            hobby = []\n",
        "            for pred in predictions:\n",
        "                index = np.argpartition(pred, -3)[-3:]\n",
        "                index = index[np.argsort(pred[index])][::-1]\n",
        "                for i in index:\n",
        "                    hobby.append(self.num2hobby[str(i)])\n",
        "            predictResult = {\n",
        "                \"hobbyType\":{\n",
        "                \"name\":user_mbti\n",
        "                },\n",
        "                \"hobbies\":[\n",
        "                    {\n",
        "                        \"name\":hobby[0]\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\":hobby[1]\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\":hobby[2]\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "            return predictResult"
      ],
      "metadata": {
        "id": "htyxcL_PoqDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}